{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from preprocessing import *\n",
    "import numpy as np\n",
    "from utils.gpu import set_memory_growth\n",
    "from model import create_model\n",
    "from utils import load_points, segment_image, load_itk, world_to_voxel, create_fake_images\n",
    "from os.path import join\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 5\n",
      "batch size: 32\n",
      "batches per epoch: 20\n",
      "total iterations: 3200\n"
     ]
    }
   ],
   "source": [
    "training_dir = \"./training\"\n",
    "\n",
    "\n",
    "def get_batch(dataset_idx, vessel_idx, batch_size=32):\n",
    "    \"\"\"\n",
    "    :param dataset_idx: dataset to use\n",
    "    :param vessel_idx: vessel to use\n",
    "    :param batch_size: size of the batch gee\n",
    "    :return: a batch of data from the given dataset and vessel\n",
    "    \"\"\"\n",
    "\n",
    "#     print(\"-\", end=\"\")\n",
    "    reference_points = load_reference_points(\"./preprocessing/reference_directions.txt\")\n",
    "    probs, radii, directions, input_data = [], [], [], []\n",
    "\n",
    "    points_path = join(training_dir, \"dataset0%d/vessel%s/reference.txt\" % (dataset_idx, str(vessel_idx)))\n",
    "    points = load_points(points_path)\n",
    "\n",
    "    image, _, _ = load_itk(join(training_dir, \"dataset0%d/image0%d.mhd\" % (dataset_idx, dataset_idx)))\n",
    "    idxs = np.random.randint(300, len(points) - 300, batch_size)\n",
    "    for idx in idxs:\n",
    "        radius, direction = create_sample(idx, points, reference_points)\n",
    "\n",
    "        point = world_to_voxel(points[idx, :3])\n",
    "        patch = segment_image(image, point).copy()\n",
    "\n",
    "        if patch.shape == (19, 19, 19):\n",
    "            input_data.append(patch)\n",
    "            probs.append(1.)\n",
    "            radii.append(radius)\n",
    "            directions.append(direction)\n",
    "\n",
    "    input_data = np.asarray(input_data).reshape(-1, 19, 19, 19, 1)\n",
    "    radii = np.asarray(radii).reshape(-1, 1)\n",
    "    directions = np.asarray(directions).reshape(-1, 500)\n",
    "    probs = np.asarray(probs).reshape(-1, 1)\n",
    "    # print(input_data.shape, radii.shape, directions.shape, probs.shape)\n",
    "\n",
    "    return input_data, [probs, radii, directions]\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "batches_per_epoch = 20\n",
    "total_iterations = epochs * batch_size * batches_per_epoch\n",
    "print(\"epochs: %s\\nbatch size: %d\\nbatches per epoch: %d\\ntotal iterations: %d\" % (\n",
    "    epochs, batch_size, batches_per_epoch, total_iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate = 1e-3\n",
    "    epochs_drop = 10000 / batch_size / batches_per_epoch\n",
    "    drop = 0.1\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "lrate_callback = LearningRateScheduler(step_decay)\n",
    "set_memory_growth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "[--------------------]\n",
      "Epoch 2/5\n",
      "[--------------------]\n",
      "Epoch 3/5\n",
      "[--------------------]\n",
      "Epoch 4/5\n",
      "[--------------------]\n",
      "Epoch 5/5\n",
      "[----------"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "dataset_idx, image_idx = 0, 0\n",
    "for e in range(epochs):\n",
    "    print(\"Epoch %d/%d\\n[\" % (e + 1, epochs), end=\"\")\n",
    "    for b in range(batches_per_epoch):\n",
    "        print(\"-\", end=\"\")\n",
    "        X_batch, y_batch = get_batch(dataset_idx % 8, image_idx % 4, batch_size=batch_size)\n",
    "        model.fit(X_batch, y_batch, verbose=0, epochs=1, callbacks=[lrate_callback])\n",
    "        dataset_idx += 1\n",
    "        image_idx += 1\n",
    "    print(\"]\")\n",
    "\n",
    "model.evaluate(X_batch, y_batch)\n",
    "model.save_weights(\"./models/model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "start = time()\n",
    "get_batch(0, 0)\n",
    "end = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "\n",
    "\n",
    "reference_points = load_reference_points(\"./preprocessing/reference_directions.txt\")\n",
    "probs, radii, directions, input_data = [], [], [], []\n",
    "\n",
    "points_path = join(training_dir, \"dataset0%d/vessel%s/reference.txt\" % (0, str(0)))\n",
    "points = load_points(points_path)\n",
    "\n",
    "\n",
    "\n",
    "point1 = time()\n",
    "\n",
    "\n",
    "\n",
    "image, _, _ = load_itk(join(training_dir, \"dataset0%d/image0%d.mhd\" % (0, 0)))\n",
    "\n",
    "\n",
    "\n",
    "point2 = time()\n",
    "\n",
    "\n",
    "\n",
    "idxs = np.random.randint(300, len(points) - 300, batch_size)\n",
    "for idx in idxs:\n",
    "    p1 = time()\n",
    "    \n",
    "    radius, direction = create_sample(idx, points, reference_points)\n",
    "    \n",
    "    p2 = time()\n",
    "    \n",
    "    point = world_to_voxel(points[idx, :3])\n",
    "    patch = segment_image(image, point).copy()\n",
    "    \n",
    "    p3 = time()\n",
    "\n",
    "    if patch.shape == (19, 19, 19):\n",
    "        input_data.append(patch)\n",
    "        probs.append(1.)\n",
    "        radii.append(radius)\n",
    "        directions.append(direction)\n",
    "        \n",
    "    p4 = time()\n",
    "        \n",
    "        \n",
    "point3 = time()\n",
    "\n",
    "\n",
    "input_data = np.asarray(input_data).reshape(-1, 19, 19, 19, 1)\n",
    "radii = np.asarray(radii).reshape(-1, 1)\n",
    "directions = np.asarray(directions).reshape(-1, 500)\n",
    "probs = np.asarray(probs).reshape(-1, 1)\n",
    "\n",
    "\n",
    "end = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.41507482528686523, 1.582848310470581, 0.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(point2 - point1), (point3 - point2), (end - point3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
